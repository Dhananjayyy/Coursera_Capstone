{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width=\"400\" align=\"center\"></a>\n",
    "\n",
    "<h1><center>Decision Trees</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab exercise, you will learn a popular machine learning algorithm, Decision Tree. You will use this classification algorithm to build a model from historical data of patients, and their response to different medications. Then you use the trained decision tree to predict the class of a unknown patient, or to find a proper drug for a new patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of contents</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#about_dataset\">About the dataset</a></li>\n",
    "        <li><a href=\"#downloading_data\">Downloading the Data</a></li>\n",
    "        <li><a href=\"#pre-processing\">Pre-processing</a></li>\n",
    "        <li><a href=\"#setting_up_tree\">Setting up the Decision Tree</a></li>\n",
    "        <li><a href=\"#modeling\">Modeling</a></li>\n",
    "        <li><a href=\"#prediction\">Prediction</a></li>\n",
    "        <li><a href=\"#evaluation\">Evaluation</a></li>\n",
    "        <li><a href=\"#visualization\">Visualization</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Import the Following Libraries:\n",
    "<ul>\n",
    "    <li> <b>numpy (as np)</b> </li>\n",
    "    <li> <b>pandas</b> </li>\n",
    "    <li> <b>DecisionTreeClassifier</b> from <b>sklearn.tree</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-06T07:42:58.400Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div id=\"about_dataset\">\n",
    "    <h2>About the dataset</h2>\n",
    "    Imagine that you are a medical researcher compiling data for a study. You have collected data about a set of patients, all of whom suffered from the same illness. During their course of treatment, each patient responded to one of 5 medications, Drug A, Drug B, Drug c, Drug x and y. \n",
    "    <br>\n",
    "    <br>\n",
    "    Part of your job is to build a model to find out which drug might be appropriate for a future patient with the same illness. The feature sets of this dataset are Age, Sex, Blood Pressure, and Cholesterol of patients, and the target is the drug that each patient responded to.\n",
    "    <br>\n",
    "    <br>\n",
    "    It is a sample of binary classifier, and you can use the training part of the dataset \n",
    "    to build a decision tree, and then use it to predict the class of a unknown patient, or to prescribe it to a new patient.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div id=\"downloading_data\"> \n",
    "    <h2>Downloading the Data</h2>\n",
    "    To download the data, we will use !wget to download it from IBM Object Storage.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:30:48.825127Z",
     "start_time": "2020-05-06T07:30:46.914808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-05-06 13:00:47--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/drug200.csv\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6027 (5.9K) [text/csv]\n",
      "Saving to: 'drug200.csv'\n",
      "\n",
      "     0K .....                                                 100% 30.9M=0s\n",
      "\n",
      "2020-05-06 13:00:48 (30.9 MB/s) - 'drug200.csv' saved [6027/6027]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O drug200.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/drug200.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Did you know?__ When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, read data using pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-06T07:42:01.054Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "my_data = pd.read_csv(\"drug200.csv\", delimiter=\",\")\n",
    "my_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div id=\"practice\"> \n",
    "    <h3>Practice</h3> \n",
    "    What is the size of data? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:35:26.967151Z",
     "start_time": "2020-05-06T07:35:26.962163Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here\n",
    "my_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div href=\"pre-processing\">\n",
    "    <h2>Pre-processing</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Using <b>my_data</b> as the Drug.csv data read by pandas, declare the following variables: <br>\n",
    "\n",
    "<ul>\n",
    "    <li> <b> X </b> as the <b> Feature Matrix </b> (data of my_data) </li>\n",
    "    <li> <b> y </b> as the <b> response vector (target) </b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Remove the column containing the target name since it doesn't contain numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:33:19.905168Z",
     "start_time": "2020-05-06T07:33:19.898187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 'F', 'HIGH', 'HIGH', 25.355],\n",
       "       [47, 'M', 'LOW', 'HIGH', 13.093],\n",
       "       [47, 'M', 'LOW', 'HIGH', 10.113999999999999],\n",
       "       [28, 'F', 'NORMAL', 'HIGH', 7.797999999999999],\n",
       "       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = my_data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may figure out, some features in this dataset are categorical such as __Sex__ or __BP__. Unfortunately, Sklearn Decision Trees do not handle categorical variables. But still we can convert these features to numerical values. __pandas.get_dummies()__\n",
    "Convert categorical variable into dummy/indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:33:42.272782Z",
     "start_time": "2020-05-06T07:33:42.241903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 0, 0, 0, 25.355],\n",
       "       [47, 1, 1, 0, 13.093],\n",
       "       [47, 1, 1, 0, 10.113999999999999],\n",
       "       [28, 0, 2, 0, 7.797999999999999],\n",
       "       [61, 0, 1, 0, 18.043]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "le_sex.fit(['F','M'])\n",
    "X[:,1] = le_sex.transform(X[:,1]) \n",
    "\n",
    "\n",
    "le_BP = preprocessing.LabelEncoder()\n",
    "le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
    "X[:,2] = le_BP.transform(X[:,2])\n",
    "\n",
    "\n",
    "le_Chol = preprocessing.LabelEncoder()\n",
    "le_Chol.fit([ 'NORMAL', 'HIGH'])\n",
    "X[:,3] = le_Chol.transform(X[:,3]) \n",
    "\n",
    "X[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:33:52.003725Z",
     "start_time": "2020-05-06T07:33:51.983777Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    drugY\n",
       "1    drugC\n",
       "2    drugC\n",
       "3    drugX\n",
       "4    drugY\n",
       "Name: Drug, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = my_data[\"Drug\"]\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"setting_up_tree\">\n",
    "    <h2>Setting up the Decision Tree</h2>\n",
    "    We will be using <b>train/test split</b> on our <b>decision tree</b>. Let's import <b>train_test_split</b> from <b>sklearn.cross_validation</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:34:12.177836Z",
     "start_time": "2020-05-06T07:34:11.875765Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now <b> train_test_split </b> will return 4 different parameters. We will name them:<br>\n",
    "X_trainset, X_testset, y_trainset, y_testset <br> <br>\n",
    "The <b> train_test_split </b> will need the parameters: <br>\n",
    "X, y, test_size=0.3, and random_state=3. <br> <br>\n",
    "The <b>X</b> and <b>y</b> are the arrays required before the split, the <b>test_size</b> represents the ratio of the testing dataset, and the <b>random_state</b> ensures that we obtain the same splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:34:14.784481Z",
     "start_time": "2020-05-06T07:34:14.634967Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3>Practice</h3>\n",
    "Print the shape of X_trainset and y_trainset. Ensure that the dimensions match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:19.034070Z",
     "start_time": "2020-05-06T07:36:19.030081Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "X_trainset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Print the shape of X_testset and y_testset. Ensure that the dimensions match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:36.585155Z",
     "start_time": "2020-05-06T07:36:36.581163Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "y_trainset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"modeling\">\n",
    "    <h2>Modeling</h2>\n",
    "    We will first create an instance of the <b>DecisionTreeClassifier</b> called <b>drugTree</b>.<br>\n",
    "    Inside of the classifier, specify <i> criterion=\"entropy\" </i> so we can see the information gain of each node.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:42.130602Z",
     "start_time": "2020-05-06T07:36:42.125614Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "drugTree # it shows the default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will fit the data with the training feature matrix <b> X_trainset </b> and training  response vector <b> y_trainset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:46.767692Z",
     "start_time": "2020-05-06T07:36:46.516293Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugTree.fit(X_trainset,y_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"prediction\">\n",
    "    <h2>Prediction</h2>\n",
    "    Let's make some <b>predictions</b> on the testing dataset and store it into a variable called <b>predTree</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:50.234597Z",
     "start_time": "2020-05-06T07:36:50.199997Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "predTree = drugTree.predict(X_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can print out <b>predTree</b> and <b>y_testset</b> if you want to visually compare the prediction to the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:36:52.975383Z",
     "start_time": "2020-05-06T07:36:52.972445Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drugY' 'drugX' 'drugX' 'drugX' 'drugX']\n",
      "40     drugY\n",
      "51     drugX\n",
      "139    drugX\n",
      "197    drugX\n",
      "170    drugX\n",
      "Name: Drug, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (predTree [0:5])\n",
    "print (y_testset [0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"evaluation\">\n",
    "    <h2>Evaluation</h2>\n",
    "    Next, let's import <b>metrics</b> from sklearn and check the accuracy of our model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:37:01.213046Z",
     "start_time": "2020-05-06T07:36:59.130799Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTrees's Accuracy:  0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"DecisionTrees's Accuracy: \", metrics.accuracy_score(y_testset, predTree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "__Accuracy classification score__ computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.  \n",
    "\n",
    "In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Practice \n",
    "Can you calculate the accuracy score without sklearn ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-06T07:41:35.985Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(X_trainset, predTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<div id=\"visualization\">\n",
    "    <h2>Visualization</h2>\n",
    "    Lets visualize the tree\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-06T07:37:31.105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Acer\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pydotplus\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    graphviz-2.38.0            |    h6538335_1011        41.0 MB  conda-forge\n",
      "    krb5-1.16.2                |    h038dc86_1000         825 KB  conda-forge\n",
      "    libarchive-3.3.3           |    hd1ea8e3_1002         4.0 MB  conda-forge\n",
      "    openssl-1.0.2p             |       hfa6e2cd_0         5.4 MB  conda-forge\n",
      "    pydotplus-2.0.2            |             py_2          23 KB  conda-forge\n",
      "    zstd-1.3.3                 |           vc14_1         1.2 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        52.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  graphviz           conda-forge/win-64::graphviz-2.38.0-h6538335_1011\n",
      "  pydotplus          conda-forge/noarch::pydotplus-2.0.2-py_2\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  anaconda                                    custom-py37_1 --> 5.3.1-py37_0\n",
      "  krb5                    pkgs/main::krb5-1.16.1-hc04afaa_7 --> conda-forge::krb5-1.16.2-h038dc86_1000\n",
      "  libarchive         pkgs/main::libarchive-3.3.3-h0643e63_5 --> conda-forge::libarchive-3.3.3-hd1ea8e3_1002\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2020.4.5~ --> pkgs/main::ca-certificates-2018.03.07-0\n",
      "  certifi            conda-forge::certifi-2020.4.5.1-py37h~ --> pkgs/main::certifi-2018.8.24-py37_1\n",
      "  pycurl             conda-forge::pycurl-7.43.0.5-py37h636~ --> pkgs/main::pycurl-7.43.0.2-py37h74b6da3_0\n",
      "  sortedcontainers   conda-forge/noarch::sortedcontainers-~ --> pkgs/main/win-64::sortedcontainers-2.0.5-py37_0\n",
      "  zstd                     pkgs/main::zstd-1.3.7-h508b16e_0 --> conda-forge::zstd-1.3.3-vc14_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  cryptography                           2.7-py37h7a1dbc1_0 --> 2.3.1-py37h74b6da3_0\n",
      "  curl                                    7.64.1-h2a8f88b_0 --> 7.61.0-h7602738_0\n",
      "  libcurl                                 7.64.1-h2a8f88b_0 --> 7.61.0-h7602738_0\n",
      "  libpng                                  1.6.37-h2a8f88b_0 --> 1.6.34-h79bbb47_0\n",
      "  libssh2                                  1.8.2-h7a1dbc1_0 --> 1.8.0-hd619d38_4\n",
      "  mkl_fft                              1.0.6-py37hdbbee80_0 --> 1.0.4-py37h1e22a9b_1\n",
      "  numpy                               1.15.4-py37ha559c80_0 --> 1.15.1-py37ha559c80_0\n",
      "  numpy-base                          1.15.4-py37h8128ebf_0 --> 1.15.1-py37h8128ebf_0\n",
      "  openssl                                 1.1.1f-hfa6e2cd_0 --> 1.0.2p-hfa6e2cd_0\n",
      "  qt                                   5.9.7-vc14h73c81de_0 --> 5.9.6-vc14h1e9a669_2\n",
      "  sqlite                                  3.28.0-he774522_0 --> 3.24.0-h7602738_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libarchive-3.3.3     | 4.0 MB    |            |   0% \n",
      "\n",
      "openssl-1.0.2p       | 5.4 MB    |            |   0% \n",
      "\n",
      "graphviz-2.38.0      | 41.0 MB   |            |   0% \n",
      "\n",
      "zstd-1.3.3           | 1.2 MB    |            |   0% \n",
      "\n",
      "krb5-1.16.2          | 825 KB    |            |   0% \n",
      "\n",
      "pydotplus-2.0.2      | 23 KB     |            |   0% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[WinError 127] The specified procedure could not be found\n",
      "[WinError 127] The specified procedure could not be found\n",
      "[WinError 127] The specified procedure could not be found\n",
      "[WinError 127] The specified procedure could not be found\n",
      "[WinError 127] The specified procedure could not be found\n",
      "[WinError 127] The specified procedure could not be found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Notice: You might need to uncomment and install the pydotplus and graphviz libraries if you have not installed these before\n",
    "!conda install -c conda-forge pydotplus -y\n",
    "!conda install -c conda-forge python-graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T07:37:20.280805Z",
     "start_time": "2020-05-06T07:37:20.264848Z"
    },
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydotplus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7cd0e99cea10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydotplus'"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import tree\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "filename = \"drugtree.png\"\n",
    "featureNames = my_data.columns[0:5]\n",
    "targetNames = my_data[\"Drug\"].unique().tolist()\n",
    "out=tree.export_graphviz(drugTree,feature_names=featureNames, out_file=dot_data, class_names= np.unique(y_trainset), filled=True,  special_characters=True,rotate=False)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png(filename)\n",
    "img = mpimg.imread(filename)\n",
    "plt.figure(figsize=(100, 200))\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>Want to learn more?</h2>\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"http://cocl.us/ML0101EN-SPSSModeler\">SPSS Modeler</a>\n",
    "\n",
    "Also, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://cocl.us/ML0101EN_DSX\">Watson Studio</a>\n",
    "\n",
    "<h3>Thanks for completing this lesson!</h3>\n",
    "\n",
    "<h4>Author:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a></h4>\n",
    "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
